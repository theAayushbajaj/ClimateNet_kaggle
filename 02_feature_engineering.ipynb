{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining regions from lat/lon using DBSCAN clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "df['lon'] = (df['lon'] + 180) % 360 - 180 # converting to 180 scale\n",
    "dbscan = DBSCAN(eps=50/6371., \n",
    "                min_samples=20, \n",
    "                algorithm='ball_tree', \n",
    "                metric='haversine').fit(np.radians(df[['lat','lon']]))\n",
    "df['region'] = dbscan.labels_\n",
    "\n",
    "print(np.unique(dbscan.labels_,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def preprocess(data, train, standardize=True):\n",
    "    data = data.drop('PSL',axis=1)  # removing as the column values are almost the same with PS\n",
    "    #data['lon'] = (data['lon'] + 180) % 360 - 180\n",
    "    if train:\n",
    "        # drop duplicates\n",
    "        data.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Extract year, month, and day from the 'time' column\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "\n",
    "    # Create interaction features\n",
    "    data['U850_V850_interaction'] = data['U850'] * data['V850']\n",
    "    data['TMQ_T200_interaction'] = data['TMQ'] * data['T200']\n",
    "    data['TMQ_T500_interaction'] = data['TMQ'] * data['T500']\n",
    "    data['TMQ_TS_interaction'] = data['TMQ'] * data['TS']\n",
    "    data['TMQ_TREFHT_interaction'] = data['TMQ'] * data['TREFHT']\n",
    "\n",
    "    if train:\n",
    "        # Splitting the dataset into features (X) and target (y)\n",
    "        X = data.drop(columns=['Label'])  # Assuming 'Label' is your target column\n",
    "        y = data['Label']\n",
    "    else:\n",
    "        X = data\n",
    "        y = None\n",
    "\n",
    "    # Separate columns to avoid standardization\n",
    "    X_region = X['region']\n",
    "    X_lat_lon = X[['lat', 'lon']]\n",
    "    X_temporal = X[['year', 'month', 'day']]\n",
    "    X = X.drop(columns=['lat', 'lon', 'year', 'month', 'day'])\n",
    "    \n",
    "    scaler = StandardScaler() if standardize else MinMaxScaler()\n",
    "    X_normalized = X.groupby('region').transform(lambda x: scaler.fit_transform(x.values[:,np.newaxis]).ravel())\n",
    "    \n",
    "    # Combining back the non-standardized columns\n",
    "    X_region = X_region.reset_index(drop=True)\n",
    "    X_lat_lon = X_lat_lon.reset_index(drop=True)\n",
    "    X_temporal = X_temporal.reset_index(drop=True)\n",
    "    X_normalized = X_normalized.reset_index(drop=True)\n",
    "\n",
    "    X = pd.concat([X_temporal, X_normalized], axis=1)\n",
    "\n",
    "    # Transforming month and day into cyclical features\n",
    "    X['sin_month'] = np.sin(2 * np.pi * X['month'] / 12)\n",
    "    X['cos_month'] = np.cos(2 * np.pi * X['month'] / 12)\n",
    "    X['sin_day'] = np.sin(2 * np.pi * X['day'] / 30)\n",
    "    X['cos_day'] = np.cos(2 * np.pi * X['day'] / 30)\n",
    "\n",
    "    # Dropping the original month and day columns\n",
    "    X = X.drop(columns=['month', 'day', 'year'])\n",
    "\n",
    "    if train:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(16, 12))\n",
    "plt.rc('font', size=15)\n",
    "\n",
    "data = df[(df['Region'] == 0) & (df.index.year.isin([1996,1997]))]\n",
    "mean_resampled_data = data.resample('D').mean()\n",
    "std_resampled_data = data.resample('D').std()\n",
    "\n",
    "standardized_data = mean_resampled_data / std_resampled_data\n",
    "\n",
    "# Handle any missing data\n",
    "standardized_data = standardized_data.interpolate(method='spline', order=3)\n",
    "result = seasonal_decompose(standardized_data['TMQ'], model='additive')\n",
    "fig = result.plot()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
