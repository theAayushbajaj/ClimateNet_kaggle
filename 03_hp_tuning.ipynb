{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'learning_rate': [3e-3,3e-4],\n",
    "    'num_epochs': [2000],\n",
    "    'regularization': ['L2'],\n",
    "    'gamma': [2.0, 3.0],\n",
    "    'class_weights':[[0.42411666, 8.17534247, 1.923672],[0.42411666, 8.5, 2.0]],\n",
    "    'alpha':[[0,0,0],[0.15, 0.90, 0.6],[0.20, 0.95, 0.6]]\n",
    "}\n",
    "\n",
    "best_params_list = []  # To store the best parameters for each model\n",
    "best_models = []       # To store the best models for each region\n",
    "\n",
    "\n",
    "# Split the data using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean.values, y_clean.values, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV (without TimeSeriesSplit)\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)  # cv=5 as an example\n",
    "\n",
    "# Train the model using GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Save the best hyperparameters and the best model\n",
    "best_params_list.append(grid_search.best_params_)\n",
    "best_models.append(grid_search.best_estimator_)\n",
    "\n",
    "# Optionally, you can print out the results for each iteration\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
