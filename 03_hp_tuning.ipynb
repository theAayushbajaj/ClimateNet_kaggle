{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import numpy as np\n",
    "from self_learn import LogisticRegression\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "%store -r X_val\n",
    "%store -r y_train\n",
    "%store -r y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterOptimizer:\n",
    "    def __init__(self, estimator, scoring='accuracy', cv=None):\n",
    "        self.estimator = estimator\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv  # Custom cross-validator\n",
    "\n",
    "    def grid_search(self, param_grid):\n",
    "        self.optimizer = GridSearchCV(\n",
    "            estimator=self.estimator,\n",
    "            param_grid=param_grid,\n",
    "            scoring=self.scoring,\n",
    "            cv=self.cv  # Use custom cross-validator\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def random_search(self, param_distributions, n_iter=10):\n",
    "        self.optimizer = RandomizedSearchCV(\n",
    "            estimator=self.estimator,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter=n_iter,\n",
    "            scoring=self.scoring,\n",
    "            cv=self.cv  # Use custom cross-validator\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def bayesian_search(self, search_spaces, n_iter=50, n_points=1):\n",
    "        self.optimizer = BayesSearchCV(\n",
    "            estimator=self.estimator,\n",
    "            search_spaces=search_spaces,\n",
    "            n_iter=n_iter,\n",
    "            scoring=self.scoring,\n",
    "            cv=self.cv,  # Use custom cross-validator\n",
    "            n_points=n_points\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.optimizer.fit(X_train, y_train)\n",
    "        return self\n",
    "\n",
    "    def best_params(self):\n",
    "        return self.optimizer.best_params_\n",
    "\n",
    "    def best_score(self):\n",
    "        return self.optimizer.best_score_\n",
    "\n",
    "    def best_estimator(self):\n",
    "        return self.optimizer.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_val, y_train, y_val are your training and validation sets\n",
    "# Concatenate your training and validation sets\n",
    "X = np.concatenate((X_train, X_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# Create the test_fold array\n",
    "test_fold = [-1]*len(X_train) + [0]*len(X_val)  # -1 for training, 0 for validation\n",
    "\n",
    "# Create the PredefinedSplit cross-validator\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "weights = utils.get_class_weights(len(y), 3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24563, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 144 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n144 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/microbot/miniconda/envs/eda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/microbot/Masters/IFT6390_FundamentalsOfML/Kaggle_competition/self_learn.py\", line 104, in fit\n    val_accuracy = np.mean(y_val == self.predict(X_val)) if self.validation else None\n                                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/microbot/Masters/IFT6390_FundamentalsOfML/Kaggle_competition/self_learn.py\", line 143, in predict\n    logits = X.dot(self.weights) + self.bias\n             ^^^^^\nAttributeError: 'NoneType' object has no attribute 'dot'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m3e-2\u001b[39m,\u001b[39m3e-3\u001b[39m,\u001b[39m3e-4\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m2000\u001b[39m, \u001b[39m2500\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclass_weights\u001b[39m\u001b[39m'\u001b[39m:[[\u001b[39m0.42411666\u001b[39m, \u001b[39m8.17534247\u001b[39m, \u001b[39m1.923672\u001b[39m],[\u001b[39m0.42411666\u001b[39m, \u001b[39m8.5\u001b[39m, \u001b[39m2.0\u001b[39m]]\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[39m# Perform Grid Search\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m optimizer\u001b[39m.\u001b[39;49mgrid_search(param_grid)\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGrid Search Best Params:\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m.\u001b[39mbest_params())\n",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36mHyperparameterOptimizer.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X_train, y_train):\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/eda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda/envs/eda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniconda/envs/eda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/miniconda/envs/eda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 144 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n144 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/microbot/miniconda/envs/eda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/microbot/Masters/IFT6390_FundamentalsOfML/Kaggle_competition/self_learn.py\", line 104, in fit\n    val_accuracy = np.mean(y_val == self.predict(X_val)) if self.validation else None\n                                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/microbot/Masters/IFT6390_FundamentalsOfML/Kaggle_competition/self_learn.py\", line 143, in predict\n    logits = X.dot(self.weights) + self.bias\n             ^^^^^\nAttributeError: 'NoneType' object has no attribute 'dot'\n"
     ]
    }
   ],
   "source": [
    "# Initialize the optimizer\n",
    "optimizer = HyperparameterOptimizer(estimator, cv=ps)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [3e-2,3e-3,3e-4],\n",
    "    'num_epochs': [2000, 2500],\n",
    "    'regularization': ['L1','L2'],\n",
    "    'lambda_reg': [0.001, 0.01, 0.1],\n",
    "    'gamma': [2.0, 3.0],\n",
    "    'class_weights':[[0.42411666, 8.17534247, 1.923672],[0.42411666, 8.5, 2.0]]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "optimizer.grid_search(param_grid).fit(X, y)\n",
    "print(\"Grid Search Best Params:\", optimizer.best_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Random Search\n",
    "optimizer.random_search(param_grid, n_iter=10).fit(X, y)\n",
    "print(\"Random Search Best Params:\", optimizer.best_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search spaces for Bayesian Optimization\n",
    "search_spaces = {\n",
    "    'C': Real(0.1, 100, prior='log-uniform'),\n",
    "    'gamma': Real(0.001, 1, prior='log-uniform'),\n",
    "    'kernel': Categorical(['rbf'])\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "optimizer.bayesian_search(search_spaces, n_iter=50).fit(X, y)\n",
    "print(\"Bayesian Optimization Best Params:\", optimizer.best_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'learning_rate': [3e-3,3e-4],\n",
    "    'num_epochs': [2000],\n",
    "    'regularization': ['L2'],\n",
    "    'gamma': [2.0, 3.0],\n",
    "    'class_weights':[[0.42411666, 8.17534247, 1.923672],[0.42411666, 8.5, 2.0]],\n",
    "    'alpha':[[0,0,0],[0.15, 0.90, 0.6],[0.20, 0.95, 0.6]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []  # To store the best parameters for each model\n",
    "best_models = []       # To store the best models for each region\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV (without TimeSeriesSplit)\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)  # cv=5 as an example\n",
    "\n",
    "# Train the model using GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Save the best hyperparameters and the best model\n",
    "best_params_list.append(grid_search.best_params_)\n",
    "best_models.append(grid_search.best_estimator_)\n",
    "\n",
    "# Optionally, you can print out the results for each iteration\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
